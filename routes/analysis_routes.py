
from fastapi import APIRouter, HTTPException, Depends, Request
from typing import Dict, Any, Optional
import json
import time
import re  # Add missing 're' import for regex
from urllib.parse import urlparse

import openai
from models import Query
from utils.logging_utils import log_timing, logger
from utils.web_scraper import scrape_dynamic_page
from utils.visitor_utils import get_visitor_count  # Fixed import statement
from utils.analysis_utils import (
    extract_json,
    generate_prompts, 
    generate_competitor_prompts,
    generate_recommendations_summary_prompt,
    generate_competitor_strengths_summary_prompt,
    generate_design_prompt,
    get_prompt_by_type,
    analyze_with_openai  # Now this is an async function
)

router = APIRouter()

@router.post("/get_suggestions")
async def get_suggestions(query: Query):
    logger.info("‚úÖ get_suggestions k√∂rs!")
    logger.info("Query-data: %s", query.dict())
    
    total_start_time = time.time()
    
    try:
        logger.info("Validerar indata...")
        if not openai.api_key:
            logger.error("OpenAI API-nyckel saknas")
            raise HTTPException(status_code=500, detail="OpenAI API-nyckel saknas.")
        if not query.url:
            logger.error("URL saknas i f√∂rfr√•gan")
            raise HTTPException(status_code=400, detail="URL kr√§vs f√∂r analys.")
        result = urlparse(query.url)
        if not all([result.scheme, result.netloc]):
            logger.error("Ogiltig URL: %s", query.url)
            raise HTTPException(status_code=400, detail="Ogiltig URL angiven.")
    except HTTPException as e:
        logger.error("HTTPException: %s", e.detail)
        raise e
    except Exception as e:
        logger.error("Ett ov√§ntat fel intr√§ffade: %s", str(e))
        raise HTTPException(status_code=500, detail="Internt serverfel.")

    logger.info("üîç BACKEND: b√∂rjar scrape och analys")
    scrape_start = time.time()
    extracted_data = scrape_dynamic_page(query.url)
    scrape_time = time.time() - scrape_start
    logger.info(f"‚úÖ BACKEND: scraping klar p√• {scrape_time:.2f}s")

    # Kontrollera om det √§r en konkurrentanalys
    if query.is_competitor:
        # Anv√§nd konkurrentanalys-promptar
        logger.info("Genererar promptar f√∂r konkurrentanalys")
        seo_prompt, ux_prompt, content_prompt = generate_competitor_prompts(extracted_data, query.url)
        
        logger.info("Skickar konkurrentanalys-promptar till OpenAI")
        openai_start = time.time()
        analysis_results = await analyze_with_openai([seo_prompt, ux_prompt, content_prompt])
        openai_time = time.time() - openai_start
        logger.info(f"‚úÖ OpenAI-analys klar p√• {openai_time:.2f}s")
        
        if len(analysis_results) != 3:
            logger.error("Ofullst√§ndig analys fr√•n OpenAI")
            raise HTTPException(status_code=500, detail="Ofullst√§ndig analys fr√•n OpenAI.")

        # Bearbeta GPT-svaren f√∂r konkurrentanalys
        json_parse_start = time.time()
        try:
            seo_data = json.loads(extract_json(analysis_results[0]))
            ux_data = json.loads(extract_json(analysis_results[1]))
            content_data = json.loads(extract_json(analysis_results[2]))
        except Exception as e:
            logger.error("Fel vid tolkning av AI-svar f√∂r konkurrentanalys: %s", str(e))
            seo_data = {"summary": "", "observations": [], "recommendations": ""}
            ux_data = {"summary": "", "observations": [], "recommendations": ""}
            content_data = {"summary": "", "observations": [], "recommendations": ""}
        json_parse_time = time.time() - json_parse_start
        logger.info(f"‚úÖ JSON-parsning klar p√• {json_parse_time:.2f}s")
        
        # Bearbeta designanalys f√∂r konkurrent
        logger.info("Genererar designanalys f√∂r konkurrent")
        design_prompt = generate_design_prompt(extracted_data, query.url)
        design_start = time.time()
        design_response_raw = (await analyze_with_openai([design_prompt]))[0]
        design_time = time.time() - design_start
        logger.info(f"‚úÖ Designanalys klar p√• {design_time:.2f}s")
        
        try:
            design_score = json.loads(extract_json(design_response_raw))
            for key in ["usability", "aesthetics", "performance"]:
                if key not in design_score:
                    design_score[key] = 0
        except Exception as e:
            logger.error("Fel vid tolkning av design score: %s", str(e))
            design_score = {
                "usability": 0,
                "aesthetics": 0,
                "performance": 0,
                "comment": "Kunde inte tolka designanalys."
            }
        
        # Sammanfattning av konkurrentens styrkor
        logger.info("Genererar sammanfattning av konkurrentens styrkor")
        strengths_prompt = generate_competitor_strengths_summary_prompt(
            analysis_results[0], analysis_results[1], analysis_results[2]
        )
        
        strengths_start = time.time()
        strengths_response = (await analyze_with_openai([strengths_prompt]))[0]
        strengths_time = time.time() - strengths_start
        logger.info(f"‚úÖ Styrkesesammanfattning klar p√• {strengths_time:.2f}s")
        
        try:
            strengths_summary = json.loads(extract_json(strengths_response))
            for key in ["seo_strengths", "ux_strengths", "content_strengths", "overall_strengths"]:
                if key not in strengths_summary:
                    strengths_summary[key] = ""
        except Exception as e:
            logger.error("Fel vid tolkning av styrkesesammanfattning: %s", str(e))
            strengths_summary = {
                "seo_strengths": "",
                "ux_strengths": "",
                "content_strengths": "",
                "overall_strengths": "Kunde inte sammanfatta styrkor."
            }

        domain_only = result.netloc
        
        total_time = time.time() - total_start_time
        logger.info(f"üéâ Konkurrentanalys slutf√∂rd p√• totalt {total_time:.2f}s")
        
        # L√§gg till prestandam√§tningar i svaret
        perf_metrics = {
            "scrape_time": round(scrape_time, 2),
            "openai_analysis_time": round(openai_time, 2),
            "design_analysis_time": round(design_time, 2),
            "strengths_summary_time": round(strengths_time, 2),
            "total_processing_time": round(total_time, 2)
        }
        
        return {
            "seo_analysis": seo_data,
            "ux_analysis": ux_data,
            "content_analysis": content_data,
            "designScore": design_score,
            "strengths_summary": strengths_summary,
            "visitors_per_month": get_visitor_count(domain_only),
            "is_competitor": True,
            "performance_metrics": perf_metrics
        }
    # Hantera olika analystyper
    elif query.analysis_type and query.analysis_type in [
        "landing_page", "product_page", "trust_check", "brand_analysis", "mobile_experience"
    ]:
        # Anv√§nd specifik prompt baserad p√• analystyp
        logger.info(f"Genererar prompt f√∂r analystyp: {query.analysis_type}")
        specific_prompt = get_prompt_by_type(query.analysis_type, extracted_data, query.url)
        
        openai_start = time.time()
        analysis_results = await analyze_with_openai([specific_prompt])
        openai_time = time.time() - openai_start
        logger.info(f"‚úÖ OpenAI-analys klar p√• {openai_time:.2f}s")
        
        if not analysis_results:
            logger.error("Ingen analys returnerades fr√•n AI")
            raise HTTPException(status_code=500, detail="Ingen analys returnerades fr√•n AI.")
            
        json_parse_start = time.time()
        try:
            json_str = extract_json(analysis_results[0])
            specialized_analysis = json.loads(json_str)
            
            # L√§gg till analystyp i svaret
            response_data = {
                "analysis_type": query.analysis_type,
                "specialized_analysis": specialized_analysis,
                "designScore": {
                    "usability": 0.5,  # Defaultv√§rden om ingen design score ber√§knas
                    "aesthetics": 0.5,
                    "performance": 0.5
                }
            }
            
            # G√∂r en design score-analys om det beh√∂vs
            if query.analysis_type in ["landing_page", "product_page"]:
                logger.info("Genererar designanalys")
                design_prompt = generate_design_prompt(extracted_data, query.url)
                design_start = time.time()
                design_result = await analyze_with_openai([design_prompt])
                design_time = time.time() - design_start
                logger.info(f"‚úÖ Designanalys klar p√• {design_time:.2f}s")
                
                try:
                    design_json_str = extract_json(design_result[0])
                    design_score = json.loads(design_json_str)
                    response_data["designScore"] = design_score
                except Exception as e:
                    logger.error("Fel vid tolkning av design score: %s", str(e))
            
            # L√§gg till dom√§ninfo
            domain_only = result.netloc
            visitor_start = time.time()
            response_data["visitors_per_month"] = get_visitor_count(domain_only)
            visitor_time = time.time() - visitor_start
            logger.info(f"‚úÖ Bes√∂kare h√§mtade p√• {visitor_time:.2f}s")
            
            # L√§gg till prestandam√§tningar
            total_time = time.time() - total_start_time
            logger.info(f"üéâ Specialiserad analys slutf√∂rd p√• totalt {total_time:.2f}s")
            
            response_data["performance_metrics"] = {
                "scrape_time": round(scrape_time, 2),
                "openai_analysis_time": round(openai_time, 2),
                "design_analysis_time": round(design_time if 'design_time' in locals() else 0, 2),
                "visitor_lookup_time": round(visitor_time, 2),
                "total_processing_time": round(total_time, 2)
            }
            
            return response_data
            
        except Exception as e:
            logger.error("Fel vid tolkning av AI-svaret: %s", str(e))
            raise HTTPException(status_code=500, detail=f"Kunde inte tolka AI-svaret: {str(e)}")
    else:
        # Anv√§nd den befintliga SEO, UX och inneh√•llsanalysen som tidigare
        logger.info("Genererar standardpromptar f√∂r SEO, UX och inneh√•llsanalys")
        seo_prompt, ux_prompt, content_prompt = generate_prompts(extracted_data, query.url)
        
        openai_start = time.time()
        analysis_results = await analyze_with_openai([seo_prompt, ux_prompt, content_prompt])
        openai_time = time.time() - openai_start
        logger.info(f"‚úÖ OpenAI-analys klar p√• {openai_time:.2f}s")
        
        if len(analysis_results) != 3:
            logger.error("Ofullst√§ndig analys fr√•n OpenAI")
            raise HTTPException(status_code=500, detail="Ofullst√§ndig analys fr√•n OpenAI.")

        # --------------------------------------------
        # Bearbeta GPT-svaren f√∂r SEO, UX och Inneh√•ll
        # --------------------------------------------
        json_parse_start = time.time()
        # Bearbeta SEO-analys
        seo_raw = analysis_results[0]
        try:
            seo_json_str = extract_json(seo_raw)
            seo_data = json.loads(seo_json_str)
        except Exception as e:
            logger.error(f"Fel vid tolkning av SEO-analys: {e}")
            seo_data = {"summary": "", "observations": [], "recommendations": ""}

        # Bearbeta UX-analys
        ux_raw = analysis_results[1]
        try:
            ux_json_str = extract_json(ux_raw)
            ux_data = json.loads(ux_json_str)
        except Exception as e:
            logger.error(f"Fel vid tolkning av UX-analys: {e}")
            ux_data = {"summary": "", "observations": [], "recommendations": ""}

        # Bearbeta Inneh√•lls-analys
        content_raw = analysis_results[2]
        try:
            content_json_str = extract_json(content_raw)
            content_data = json.loads(content_json_str)
        except Exception as e:
            logger.error(f"Fel vid tolkning av inneh√•llsanalys: {e}")
            content_data = {"summary": "", "observations": [], "recommendations": ""}
            
        json_parse_time = time.time() - json_parse_start
        logger.info(f"‚úÖ JSON-parsning klar p√• {json_parse_time:.2f}s")

        # --------------------------------------------
        # Bearbeta Designanalys
        # --------------------------------------------
        logger.info("Genererar designanalys")
        design_prompt = generate_design_prompt(extracted_data, query.url)
        design_start = time.time()
        design_response_raw = (await analyze_with_openai([design_prompt]))[0]
        design_time = time.time() - design_start
        logger.info(f"‚úÖ Designanalys klar p√• {design_time:.2f}s")
        
        logger.debug("R√•tt GPT svar f√∂r design: %s", design_response_raw[:500] + "...")
        
        try:
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', design_response_raw, re.DOTALL)
            if json_match:
                clean_json_str = json_match.group(1)
            else:
                json_match = re.search(r'(\{.*?\})', design_response_raw, re.DOTALL)
                if json_match:
                    clean_json_str = json_match.group(1)
                else:
                    raise ValueError("Ingen giltig JSON hittades")
            design_score = json.loads(clean_json_str)
            for key in ["usability", "aesthetics", "performance"]:
                if key not in design_score:
                    design_score[key] = 0
            if "comment" not in design_score:
                design_score["comment"] = "Ingen kommentar fr√•n GPT."
        except (json.JSONDecodeError, ValueError) as e:
            logger.error(f"Kunde inte tolka JSON-svar fr√•n GPT: {e}")
            design_score = {
                "usability": 0,
                "aesthetics": 0,
                "performance": 0,
                "comment": "GPT svarade inte med giltigt JSON."
            }

        # --------------------------------------------
        # Bearbeta Sammanfattning av rekommendationer
        # --------------------------------------------
        logger.info("Genererar rekommendationssammanfattning")
        summary_prompt = generate_recommendations_summary_prompt(
            analysis_results[0], analysis_results[1], analysis_results[2]
        )
        summary_start = time.time()
        summary_response = (await analyze_with_openai([summary_prompt]))[0]
        summary_time = time.time() - summary_start
        logger.info(f"‚úÖ Rekommendationssammanfattning klar p√• {summary_time:.2f}s")
        
        try:
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', summary_response, re.DOTALL)
            if json_match:
                clean_json_str = json_match.group(1)
            else:
                json_match = re.search(r'(\{.*?\})', summary_response, re.DOTALL)
                if json_match:
                    clean_json_str = json_match.group(1)
                else:
                    raise ValueError("Ingen giltig JSON hittades i GPT-svaret.")
            recommendations_summary = json.loads(clean_json_str)
            for key in ["seo_recommendations", "ux_recommendations", "content_recommendations", "overall_summary"]:
                if key not in recommendations_summary:
                    recommendations_summary[key] = ""
        except Exception as e:
            logger.error(f"Fel vid tolkning av sammanfattade rekommendationer: {e}")
            recommendations_summary = {
                "seo_recommendations": "",
                "ux_recommendations": "",
                "content_recommendations": "",
                "overall_summary": "Inga rekommendationer kunde genereras."
            }
            
        domain_only = result.netloc
        visitor_start = time.time()
        visitor_count = get_visitor_count(domain_only)
        visitor_time = time.time() - visitor_start
        logger.info(f"‚úÖ Bes√∂kare h√§mtade p√• {visitor_time:.2f}s")
        
        total_time = time.time() - total_start_time
        logger.info(f"üéâ Standardanalys slutf√∂rd p√• totalt {total_time:.2f}s")
        
        # L√§gger till prestandam√§tningar i svaret
        perf_metrics = {
            "scrape_time": round(scrape_time, 2),
            "openai_analysis_time": round(openai_time, 2),
            "json_parse_time": round(json_parse_time, 2),
            "design_analysis_time": round(design_time, 2),
            "recommendations_time": round(summary_time, 2),
            "visitor_lookup_time": round(visitor_time, 2),
            "total_processing_time": round(total_time, 2)
        }
        
        return {
            "seo_analysis": seo_data,
            "ux_analysis": ux_data,
            "content_analysis": content_data,
            "designScore": design_score,
            "recommendations_summary": recommendations_summary,
            "visitors_per_month": visitor_count,
            "performance_metrics": perf_metrics
        }
